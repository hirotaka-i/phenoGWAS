GRID = expand.grid(1:length(BinomT), 1:length(predictors))
temp = mclapply(1:nrow(GRID), cox.stats.func, mc.cores = 2)
temp2 = unlist(temp)
temp2 = do.call(rbind, temp)
View(temp2)
OUTCOME = "DEMENTIA"
PREDICTOR = "grsZ"
print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
var(cohort$OUTCOME, na.rm = T)
var(cohort$PREDICTOR, na.rm = T)
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
View(cohort)
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
View(time2follow)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
View(cohort_by_first_event)
temp = cohort_by_first_event %>% select(ID, OUTCOME, TSTART, TSTOP)
temp = cohort_by_first_event %>% select(ID, OUTCOME, TSTART,BEGIN, END)
View(temp)
temp = cohort %>% select(ID, OUTCOME, TSTART,BEGIN, END)
View(temp)
ltg$PREDICTOR = 1
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
temp = cohort %>% select(ID, OUTCOME, TSTART,BEGIN, END) %>%
group_by(ID) %>%
mutate(TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
ltg %>% filter(ID == "3233") %>% select(select(ID, OUTCOME, TSTART)
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
if(nrow(cohort)==0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoData", "NoData", "NoData", "NoData", "NoData")
}else if(var(cohort$OUTCOME, na.rm = T) == 0 | var(cohort$PREDICTOR, na.rm = T) == 0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoVar", "NoVar", "NoVar", "NoVar", "NoVar")
}else{
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
testCox = try(coxph(eval(parse(text = MODELS[i,2])), data = cohort),silent = T)
# Some can't converge by REML so use alternative method
if(class(testCox)[1]=='try-error'){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "OverFlow", "OverFlow", "OverFlow", "OverFlow", "OverFlow")
}else{
temp = summary(testCox)$coefficients
betas <- temp[,1]
se <- temp[,3]
zval <- temp[,4]
pval <- temp[,5]
NinSet = paste('E', testCox$nevent, '/N', testCox$n, sep='')
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, betas, se, zval, pval, NinSet)
}
}
sumstat
}
ltg %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART)
temp = cohort_by_first_event %>% select(ID, OUTCOME, TSTART,BEGIN, END)
temp %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART, BEGIN, END)
temp = cohort %>% select(ID, OUTCOME, TSTART,BEGIN, END) %>%
group_by(ID) %>%
mutate(TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
temp %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART, TSTOP)
ltg %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART)
temp = cohort %>% select(ID, OUTCOME, TSTART,BEGIN, END) %>% filter(ID == "3233")
temp %>% mutate(TSTART = TSTART - first(TSTART)) %>%
mutate(TSTOP = lead(TSTART))
temp = cohort %>% select(ID, OUTCOME, TSTART,BEGIN, END) %>% filter(ID == "3233")
temp
temp = cohort_by_first_event %>% select(ID, OUTCOME, TSTART,BEGIN, END) %>% filter(ID == "3233")
temp
temp %>% mutate(TSTART = TSTART - first(TSTART)) %>%
mutate(TSTOP = lead(TSTART))
temp %>% mutate(TSTART = TSTART - first(TSTART)) %>%
mutate(TSTOP = lead(TSTART),
OUTCOME = lead(OUTCOME))
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort_by_first_event %>% select(ID, OUTCOME, TSTART,BEGIN, END) %>% filter(ID == "3233")
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
cohort %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART, TSTOP)
OUTCOME = "DEMENTIA"
PREDICTOR = "grsZ"
print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
cohort %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART, TSTOP)
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
cohort %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART, TSTOP, SurvObj1)
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
head(cohort$SurvObj1)
cohort %>% filter(ID == "3233") %>% select(ID, OUTCOME, TSTART, TSTOP, SurvObj1)
cohort %>% filter(ID == "3233") %>%
mutate(SurvObj1 = as.character(SurvObj1)) %>%
select(ID, OUTCOME, TSTART, TSTOP, SurvObj1)
cohort %>% filter(ID == "3233") %>%
mutate(SurvObj1 = as.character(SurvObj1))
cohort %>% filter(ID == "3233")
cohort %>% filter(ID == "3233")
cohort %>% filter(ID == "3233") %>%
mutate(SurvObj1 = unlist(SurvObj1)) %>%
select(ID, OUTCOME, TSTART, TSTOP, SurvObj1)
testCox = try(coxph(eval(parse(text = MODELS[i,2])), data = cohort),silent = T)
testCox
coxph(eval(parse(text = MODELS[i,2])), data = cohort),silent = T)
MODELS[i,2]
coxph(eval(parse(text = paste(MODELS[i,2])), data = cohort)
)
coxph(eval(parse(text = paste(MODELS[i,2])), data = cohort)
)
coxph(eval(parse(text = MODELS[i,2])), data = cohort)
coxph(eval(parse(text = MODELS[i,2])), data = cohort)
i
coxph(eval(parse(text = MODELS[i,2])), data = cohort)
View(cohort)
coxph(SurvObj1 ~ PC1, data = cohort)
cohort %>% filter(TSTART == TSTOP)
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
cohort %>% filter(TSTART == TSTOP)
cohort %>% filter(TSTART == TSTOP) %>% select(ID, TSTART, TSTOP, BEGIN, END)
ltg %>% filter(ID == "3123") %>% select(ID, OUTCOME, TSTART)
cohort_by_first_event %>% filter(ID == "3123") %>% select(ID, OUTCOME, TSTART)
cohort %>% filter(ID == "3123") %>% select(ID, OUTCOME, TSTART, TSTOP)
cohort %>% filter(TSTART == TSTOP) %>% filter(ID =="3123")
cohort %>% filter(TSTART == TSTOP) %>% filter(ID =="3123") %>% select(ID, OUTCOME, TSTART, TSTOP)
ltg %>% filter(ID == "3123") %>% select(ID, OUTCOME, TSTART)
cohort_by_first_event %>% filter(ID == "3123") %>% select(ID, OUTCOME, TSTART)
cohort %>% filter(ID == "3123") %>% select(ID, OUTCOME, TSTART, TSTOP)
cohort %>% filter(TSTART == TSTOP) %>% filter(ID =="3123") %>% select(ID, OUTCOME, TSTART, TSTOP)
getwd()
######################################################################################################
ltg_all=fread('../data/LTGall.csv') %>% data.frame %>%
filter(STUDY_NAME != "Predict") %>%
rename(COHORT = STUDY_NAME) %>%
mutate(COHORT= case_when(
COHORT == "Coriell" ~ "NET-PD_LS1",
COHORT == "SCOPA" ~ "PROPARK",
COHORT == "PreCEPT" ~ "PRECEPT",
COHORT == "ParkFit" ~ "PARKFIT",
COHORT == "ParkWest" ~ "PARKWEST",
COHORT == "Udall" ~ "UDALL",
TRUE ~ COHORT
)) %>%
select(c("COHORT", "ID", Covs, BasicT, BinomT, PCs, predictors))
Oslo = HYUPDRSg %>%
mutate(COHORT = "Oslo") %>%
select(names(ltg_all))
data_all = rbind(ltg_all, Oslo) %>%
arrange(COHORT)
N_VARS = 2 + length(c(Covs, BasicT, BinomT, PCs))
STUDY = COHORTS[i]
OUTCOME = "DEMENTIA"
PREDICTOR = "grsZ"
print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
cohort %>% filter(TSTART == TSTOP) %>% filter(ID =="3123") %>% select(ID, OUTCOME, TSTART, TSTOP)
cohort %>% filter(TSTART == TSTOP)
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
coxph(eval(parse(text = MODELS[i,2])), data = cohort)
coxph(eval(parse(text = paste(MODELS[i,2]))), data = cohort)
cox.stats.func <- function(x){
STUDY = COHORTS[i]
OUTCOME = "DEMENTIA"
PREDICTOR = "grsZ"
print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
ltg = ltg %>% select(-one_of(predictors))
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
if(nrow(cohort)==0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoData", "NoData", "NoData", "NoData", "NoData")
}else if(var(cohort$OUTCOME, na.rm = T) == 0 | var(cohort$PREDICTOR, na.rm = T) == 0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoVar", "NoVar", "NoVar", "NoVar", "NoVar")
}else{
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
testCox = try(coxph(eval(parse(text = paste(MODELS[i,2]))), data = cohort),silent = T)
# Some can't converge by REML so use alternative method
if(class(testCox)[1]=='try-error'){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "OverFlow", "OverFlow", "OverFlow", "OverFlow", "OverFlow")
}else{
temp = summary(testCox)$coefficients
betas <- temp[,1]
se <- temp[,3]
zval <- temp[,4]
pval <- temp[,5]
NinSet = paste('E', testCox$nevent, '/N', testCox$n, sep='')
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, betas, se, zval, pval, NinSet)
}
}
sumstat
}
t <- proc.time()
invisible(mclapply(1:nrow(GRID), cox.stats.func, mc.cores = 2))
duration3 <- (proc.time() - t)[3]
t <- proc.time()
invisible(lapply(1:nrow(GRID), cox.stats.func))
duration2 <- (proc.time() - t)[3]
# Another way is to replace missing covariates with the same value like "MISS"
GRID = expand.grid(1:length(BinomT), 1:length(predictors))
cox.stats.func <- function(x){
STUDY = COHORTS[i]
OUTCOME = BinomT[GRID[x,1]]
PREDICTOR = predictors[GRID[x,2]]
print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
ltg = ltg %>% select(-one_of(predictors))
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
if(nrow(cohort)==0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoData", "NoData", "NoData", "NoData", "NoData")
}else if(var(cohort$OUTCOME, na.rm = T) == 0 | var(cohort$PREDICTOR, na.rm = T) == 0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoVar", "NoVar", "NoVar", "NoVar", "NoVar")
}else{
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
testCox = try(coxph(eval(parse(text = paste(MODELS[i,2]))), data = cohort),silent = T)
# Some can't converge by REML so use alternative method
if(class(testCox)[1]=='try-error'){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "OverFlow", "OverFlow", "OverFlow", "OverFlow", "OverFlow")
}else{
temp = summary(testCox)$coefficients
betas <- temp[,1]
se <- temp[,3]
zval <- temp[,4]
pval <- temp[,5]
NinSet = paste('E', testCox$nevent, '/N', testCox$n, sep='')
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, betas, se, zval, pval, NinSet)
}
}
sumstat
}
t <- proc.time()
invisible(lapply(1:nrow(GRID), cox.stats.func))
duration2 <- (proc.time() - t)[3]
cox.stats.func <- function(x){
STUDY = COHORTS[i]
OUTCOME = BinomT[GRID[x,1]]
PREDICTOR = predictors[GRID[x,2]]
# print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
ltg = ltg %>% select(-one_of(predictors))
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
if(nrow(cohort)==0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoData", "NoData", "NoData", "NoData", "NoData")
}else if(var(cohort$OUTCOME, na.rm = T) == 0 | var(cohort$PREDICTOR, na.rm = T) == 0){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "NoVar", "NoVar", "NoVar", "NoVar", "NoVar")
}else{
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
testCox = try(coxph(eval(parse(text = paste(MODELS[i,2]))), data = cohort),silent = T)
# Some can't converge by REML so use alternative method
if(class(testCox)[1]=='try-error'){
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, "OverFlow", "OverFlow", "OverFlow", "OverFlow", "OverFlow")
}else{
temp = summary(testCox)$coefficients
betas <- temp[,1]
se <- temp[,3]
zval <- temp[,4]
pval <- temp[,5]
NinSet = paste('E', testCox$nevent, '/N', testCox$n, sep='')
sumstat <- cbind(STUDY, OUTCOME, PREDICTOR, betas, se, zval, pval, NinSet)
}
}
sumstat
}
t <- proc.time()
invisible(lapply(1:nrow(GRID), cox.stats.func))
duration2 <- (proc.time() - t)[3]
temp = mclapply(1:nrow(GRID), cox.stats.func, mc.cores = 2)
temp2 = do.call(rbind, temp)
# t <- proc.time()
# invisible(mclapply(1:nrow(GRID), cox.stats.func, mc.cores = 2))
# duration3 <- (proc.time() - t)[3]
# t <- proc.time()
# invisible(lapply(1:nrow(GRID), cox.stats.func))
# duration2 <- (proc.time() - t)[3]
nrow(temp2)
STUDY = COHORTS[i]
OUTCOME = "DEMENTIA"
PREDICTOR = "grsZ"
print(paste(i, x, STUDY, OUTCOME, PREDICTOR))
ltg = subset(data_all, COHORT == STUDY)
ltg$OUTCOME <- ltg[,OUTCOME]
ltg$PREDICTOR = ltg[,PREDICTOR]
testCox = try(coxph(eval(parse(text = MODELS[i,2])), data = cohort),silent = T)
time2follow = ltg %>%
arrange(TSTART) %>%
filter(!is.na(OUTCOME)) %>%
group_by(ID, .keep_all = T) %>%
mutate(BEGIN = first(TSTART),
END = last(TSTART)) %>% # BEGIN and END are identical within each ID
mutate(END = ifelse(OUTCOME==1, TSTART, END)) %>% # If 1, then END will be updated
data.frame %>%
arrange(END) %>%
distinct(ID, .keep_all = T) %>%  # take the smallest END
select(ID, BEGIN, END)
cohort_by_first_event = left_join(ltg, time2follow, by = 'ID') %>%
filter(BEGIN <= TSTART & TSTART <= END) %>% # filter observation between BEGIN and END
mutate(OUTCOME = ifelse(is.na(OUTCOME), 0, OUTCOME)) # NAs in the period replaced by 0
cohort = cohort_by_first_event %>%
arrange(TSTART) %>%
group_by(ID) %>%
mutate(BLDfDIAG = BLDfDIAG + TSTART/365.25, # Follow-up starts TSTART > 0 sometimes, Needs update
TSTART = TSTART - first(TSTART)) %>% # New baseline set 0 (Especially, ParkWest)
mutate(TSTOP = lead(TSTART), # The TSTART[i+1] will be the stop time
OUTCOME = lead(OUTCOME)) %>%  # the OUTCOME is updated by the one at the stop time
mutate(TSTOP = ifelse(is.na(TSTOP), END, TSTOP)) %>% # replace the
data.frame %>% arrange(ID, TSTART) %>%
filter(!is.na(OUTCOME)) # the basially last follow-up data will be erased (Right censored)
cohort$SurvObj1 = with(cohort, Surv(TSTART, TSTOP, OUTCOME == 1))
testCox = try(coxph(eval(parse(text = paste(MODELS[i,2]))), data = cohort),silent = T)
summary(testCox)$coefficients
